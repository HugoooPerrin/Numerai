{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      ">> Loading data...done\n",
      "\n",
      "Xtrain1: (236167, 50) \n",
      "Ytrain1: (236167,) \n",
      "Xtrain2: (157446, 50) \n",
      "Ytrain2: (157446,) \n",
      "Xvalid: (46362, 50) \n",
      "Yvalid: (46362,) \n",
      "Submit data: (243281, 50)\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      ">> Processing first stage\n",
      "\n",
      ">> Processing ExtraTrees1\n",
      "\n",
      "Step 1...done in 0h 0m 23s\n",
      "log loss : 0.6929679442851254\n",
      "\n",
      "Step 2...done in 0h 0m 22s\n",
      "log loss : 0.692999930076504\n",
      "\n",
      "Step 3...done in 0h 0m 22s\n",
      "log loss : 0.6929279930732397\n",
      "\n",
      "Step 4...done in 0h 0m 32s\n",
      "log loss : 0.693029221113938\n",
      "\n",
      "Step 5...done in 0h 0m 26s\n",
      "log loss : 0.6930742962848866\n",
      "\n",
      ">> Processing ExtraTrees2\n",
      "\n",
      "Step 1...done in 0h 0m 27s\n",
      "log loss : 0.6930435393797845\n",
      "\n",
      "Step 2...done in 0h 0m 26s\n",
      "log loss : 0.6931049820367886\n",
      "\n",
      "Step 3...done in 0h 0m 26s\n",
      "log loss : 0.693055987103797\n",
      "\n",
      "Step 4...done in 0h 0m 26s\n",
      "log loss : 0.6930150590111661\n",
      "\n",
      "Step 5...done in 0h 0m 28s\n",
      "log loss : 0.6930585546100606\n",
      "\n",
      ">> Processing SGDC\n",
      "\n",
      "Step 1...done in 0h 1m 12s\n",
      "log loss : 0.693147189433815\n",
      "\n",
      "Step 2...done in 0h 1m 8s\n",
      "log loss : 0.6931484476263565\n",
      "\n",
      "Step 3...done in 0h 0m 58s\n",
      "log loss : 0.6931473329228949\n",
      "\n",
      "Step 4...done in 0h 1m 0s\n",
      "log loss : 0.6931478831978444\n",
      "\n",
      "Step 5...done in 0h 1m 4s\n",
      "log loss : 0.6931976228743693\n",
      "\n",
      "\n",
      "First stage running time 0h 9m 47s\n",
      "\n",
      "\n",
      "---------------------------------------------\n",
      ">> Processing compilation\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 15 and input n_features is 35 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-59bc661a95b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m \u001b[0mstacking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_tune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnCores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Numerai\\main\\numerai.py\u001b[0m in \u001b[0;36mfit_tune\u001b[1;34m(self, nCores)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mgscv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnCores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mgscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompilation_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatasetToUse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatasetToUse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                                       \u001b[1;31m## COMPILATION TRAINING ON SECOND STAGE PREDICTION OF XTRAIN3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                                                                                                                           \u001b[1;31m## IF THERE IS TWO STAGES, ELSE ON XTRAIN2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[1;31m# Final prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m    483\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, raw_score, num_iteration)\u001b[0m\n\u001b[0;32m    712\u001b[0m                              \u001b[1;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                              % (self._n_features, n_features))\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[0mclass_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 15 and input n_features is 35 "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running algorithm to search best fitting model\n",
    "\"\"\"\n",
    "\n",
    "#=========================================================================================================\n",
    "#================================ 0. MODULE\n",
    "\n",
    "# Numerai class\n",
    "from numerai import Numerai\n",
    "\n",
    "# Machine Learning models\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "#================================ 1. DATA\n",
    "\n",
    "\n",
    "stacking = Numerai(stageNumber=1)\n",
    "stacking.load_data(109)\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "#================================ 2. FEATURE ENGINEERING\n",
    "\n",
    "\n",
    "# metafeature = ['variance', 'mean', 'distance']\n",
    "# stages = [2, 0, 2]\n",
    "# stacking.add_metafeature(metafeature, stages)\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "#================================ 3. MODEL ARCHITECTURE\n",
    "\n",
    "\n",
    "nCores = -1\n",
    "\n",
    "\n",
    "modelNames = ['ExtraTrees1',\n",
    "              'ExtraTrees2',\n",
    "              # 'XGBoost', \n",
    "              'SGDC',\n",
    "              'Lightgbm']\n",
    "\n",
    "models = [ExtraTreesClassifier(n_jobs = nCores, \n",
    "                               criterion = 'entropy',\n",
    "                               max_depth = 3,\n",
    "                               n_estimators = 50,\n",
    "                               bootstrap = True),\n",
    "          \n",
    "          ExtraTreesClassifier(n_jobs = nCores, \n",
    "                               criterion = 'gini',\n",
    "                               max_depth = 3,\n",
    "                               n_estimators = 50,\n",
    "                               bootstrap = True),\n",
    "          \n",
    "#           XGBClassifier(learning_rate = 0.5, \n",
    "#                         max_depth = 3, \n",
    "#                         n_estimators = 75,\n",
    "#                         nthread = nCores),\n",
    "          \n",
    "          SGDClassifier(loss = 'log', \n",
    "                        penalty = 'elasticnet', \n",
    "                        learning_rate = 'optimal',\n",
    "                        max_iter = 5,\n",
    "                        tol = None,\n",
    "                        n_jobs = nCores),\n",
    "         \n",
    "          LGBMClassifier(objective = 'binary',\n",
    "                         max_depth = 3,\n",
    "                         n_estimators = 100,\n",
    "                         n_jobs = nCores)]\n",
    "\n",
    "parameters = [{'min_samples_split' : [200, 1000],                               # ExtraTreesClassifier entropy\n",
    "               'min_samples_leaf' : [200, 1000]},\n",
    "\n",
    "              {'min_samples_split' : [200, 1000],                               # ExtraTreesClassifier gini\n",
    "               'min_samples_leaf' : [200, 1000]},\n",
    "\n",
    "#               {'subsample' : [0.5, 0.75, 1]},                                   # XGBoostClassifier\n",
    "\n",
    "              {'alpha' : [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1],            # SGDClassifier\n",
    "               'l1_ratio' : [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1]},\n",
    "\n",
    "              {# 'n_estimators': [50, 100, 200],                                  # Lightgbm\n",
    "               'num_leaves ' : [15, 40, 100, 500],\n",
    "               'min_samples_leaf' : [200, 1000],\n",
    "               'reg_lambda' : [0.001, 0.01, 0.05, 0.1, 0.5, 1]}]\n",
    "\n",
    "nFeatures = [15, 15, 35, None]\n",
    "\n",
    "baggingSteps = [5, 5, 3, 1]\n",
    "\n",
    "stages = [1, 1, 1, 2]\n",
    "\n",
    "\n",
    "for name, model, parameters, baggingSteps, nFeatures, stage in zip(modelNames, models, parameters, baggingSteps, nFeatures, stages):\n",
    "    stacking.add_model(name, model, parameters, baggingSteps, nFeatures, stage)\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "#================================ 4. TRAINING MODEL\n",
    "\n",
    "\n",
    "stacking.fit_tune(nCores)\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "#================================ 5. PREDICTION\n",
    "\n",
    "\n",
    "# stacking.submit(submissionNumber=1, week=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
